# Reservoior Computingについて
一言で言うと，中間層の再学習をしないRNNなんだけれども，数学的な特徴をとらえるのが結構めんどくさいのと，webでいい感じの文献が存在していないので，清水なりに調査をしてまとめました．

- 入力データ (u(t)): 各時刻 t に入ってくる数値のリスト。リストの要素数は入力の種類によります（例：4つのセンサーなら4個）。
- 内部状態 (x(t)): リザバー内部の各要素（ニューロン）が持つ数値のリスト。要素数はニューロンの数 Nx​ です（例：1000個）。これは計算の「途中結果」であり、時間とともに変化します。
- 出力データ (y(t)): 計算の最終結果として出す数値のリスト。要素数は出力したいものの種類によります（例：1つの数値を予測するなら1個、4種類に分類するなら4個）。
- 固定された計算ルール（重み行列）:
    Win​: 入力データ u(t) を内部状態の計算に使うための「ルール表」。大きさは (ニューロン数 Nx​) 行 × (入力要素数 Nu​) 列（例：1000行×4列）。中身はランダムな数値で、計算開始前に一度決めたら変更しません。
- W: 1つ前の内部状態 x(t−1) を現在の内部状態の計算に使うための「ルール表」。大きさは (ニューロン数 Nx​) 行 × (ニューロン数 Nx​) 列（例：1000行×1000列）。これもランダムな数値で、計算開始前に一度決めたら変更しません。
- 学習される計算ルール（重み行列）:
    Wout​: 計算された内部状態 x(t) を最終的な出力 y(t) に変換するための「ルール表」。大きさは (出力要素数 Ny​) 行 × (ニューロン数 Nx​) 列（例：1行×1000列 や 4行×1000列）。この中身は、事前にデータを使って学習し、最適化された数値です。

## ミソはどこなの？
中間層から出力層との間だけ学習させればいいので，計算コストがあまり高くないと言われているけれども，なんでそれができんのけ？という問題がある．

